[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a research scientist at SEA AI Lab. Previously, I was a PhD student at the School of Computing, National University of Singapore, under the supervision of Prof. David Hsu. I also worked closely with Prof. Wee Sun Lee. I received my bachelor\u0026rsquo;s degree from Shanghai Jiao Tong University, under the supervision of Prof. Fan Wu and Prof. Xiaofeng Gao.\nMy research mainly focuses on uncertainty modelling, reinforcement learning, graph neural networks, and their applications to robotics.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a research scientist at SEA AI Lab. Previously, I was a PhD student at the School of Computing, National University of Singapore, under the supervision of Prof. David Hsu. I also worked closely with Prof. Wee Sun Lee. I received my bachelor\u0026rsquo;s degree from Shanghai Jiao Tong University, under the supervision of Prof. Fan Wu and Prof. Xiaofeng Gao.\nMy research mainly focuses on uncertainty modelling, reinforcement learning, graph neural networks, and their applications to robotics.","tags":null,"title":"Xiao Ma","type":"authors"},{"authors":["Siwei Chen","[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","Yunfan Lu","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":[],"content":"","date":1621395239,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621395239,"objectID":"ec409c881fe38cee44684bb65cc78e41","permalink":"/publication/chen2021prompt/","publishdate":"2021-05-19T11:33:59+08:00","relpermalink":"/publication/chen2021prompt/","section":"publication","summary":"This paper presents particle-based Object Manipulation (PROMPT), a new approach to robot manipulation of novel objects ab initio, without prior object models or pre-training on a large object data set. The key element of PROMPT is a particle-based object representation, in which each particle represents a point in the object, the local geometric, physical, and other features of the point, and also its relation with other particles. Like the model-based analytic approaches to manipulation, the particle representation enables the robot to reason about the object geometry and dynamics in order to choose suitable manipulation actions. Like the data-driven approaches, the particle representation is learned online in real-time from visual sensor input, specifically, multi-view RGB images. The particle representation thus connects visual perception with robot control. PROMPT combines the benefits of both model-based reasoning and data-driven learning. We show empirically that PROMPT successfully handles a variety of everyday objects, some of which are transparent. It handles various manipulation tasks, including grasping, pushing, etc. . Our experiments also show that PROMPT outperforms a state-of-the-art data-drive grasping method on the YCB benchmark, even though it does not use any offline training data.","tags":[],"title":"Ab Initio Particle-Based Object Manipulation","type":"publication"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":[],"content":"","date":1617717103,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617717103,"objectID":"03aeebd637863645bf85d56ea292f127","permalink":"/publication/ma2021learning/","publishdate":"2020-04-06T21:51:43+08:00","relpermalink":"/publication/ma2021learning/","section":"publication","summary":"Manipulating deformable objects, such as cloth and ropes, is a long-standing challenge in robotics: their large number of degrees of freedom (DoFs) and complex non-linear dynamics make motion planning extremely difficult. This work aims to learn latent Graph dynamics for DefOrmable Object Manipulation (G-DOOM). To tackle the challenge of many DoFs and complex dynamics, G-DOOM approximates a deformable object as a sparse set of interacting keypoints and learns a graph neural network that captures abstractly the geometry and interaction dynamics of the keypoints. Further, to tackle the perceptual challenge, specifically, object self-occlusion, G-DOOM adds a recurrent neural network to track the keypoints over time and condition their interactions on the history. We then train the resulting recurrent graph dynamics model through contrastive learning in a high-fidelity simulator. For manipulation planning, G-DOOM explicitly reasons about the learned dynamics model through model-predictive control applied at each of the keypoints. We evaluate G-DOOM on a set of challenging cloth and rope manipulation tasks and show that G-DOOM outperforms a state-of-the-art method. Further, although trained entirely on simulation data, G-DOOM transfers directly to a real robot for both cloth and rope manipulation in our experiments.","tags":[],"title":"Learning Latent Graph Dynamics for Deformable Object Manipulation","type":"publication"},{"authors":["Daisheng Jin*","[**Xiao Ma***](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","Chongzhi Zhang*","Yizhuo Zhou","Jiashu Tao","[Mingyuan Zhang](https://scholar.google.com/citations?user=2QLD4fAAAAAJ\u0026hl=en)","[Haiyu Zhao](https://scholar.google.com.sg/citations?user=sMQV1ecAAAAJ\u0026hl=en)","[Shuai Yi](https://scholar.google.com.sg/citations?user=afbbNmwAAAAJ\u0026hl=en)","[Zhoujun Li](https://scholar.google.com.hk/citations?user=e-4LoEcAAAAJ\u0026hl=zh-CN)","[Xianglong Liu](https://scholar.google.com/citations?user=8VY7ZDcAAAAJ\u0026hl=zh-CN)","[Hongsheng Li](https://scholar.google.com/citations?user=BN2Ze-QAAAAJ\u0026hl=zh-CN)"],"categories":[],"content":"","date":1608817903,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608817903,"objectID":"2a83001ca93ee22c6c811718944e676e","permalink":"/publication/jin2020towards/","publishdate":"2020-12-23T21:51:43+08:00","relpermalink":"/publication/jin2020towards/","section":"publication","summary":"In this paper, we investigate the cause of the high false positive rate in Visual Relationship Detection (VRD). We observe that during training, the relationship proposal distribution is highly imbalanced: most of the negative relationship proposals are easy to identify, e.g., the inaccurate object detection, which leads to the under-fitting of low-frequency difficult proposals. This paper presents Spatially-Aware Balanced negative pRoposal sAmpling (SABRA), a robust VRD framework that alleviates the influence of false positives. To effectively optimize the model under imbalanced distribution, SABRA adopts Balanced Negative Proposal Sampling (BNPS) strategy for mini-batch sampling. BNPS divides proposals into 5 well defined sub-classes and generates a balanced training distribution according to the inverse frequency. BNPS gives an easier optimization landscape and significantly reduces the number of false positives. To further resolve the low-frequency challenging false positive proposals with high spatial ambiguity, we improve the spatial modeling ability of SABRA on two aspects: a simple and efficient multi-head heterogeneous graph attention network (MH-GAT) that models the global spatial interactions of objects, and a spatial mask decoder that learns the local spatial configuration. SABRA outperforms SOTA methods by a large margin on two human-object interaction (HOI) datasets and one general VRD dataset. ","tags":[],"title":"Towards Overcoming False Positives in Visual Relationship Detection","type":"publication"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","Siwei Chen","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":[],"content":"","date":1596721903,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596721903,"objectID":"00970f89a242d32c0d57635719e84624","permalink":"/publication/ma2020contrastive/","publishdate":"2020-08-06T21:51:43+08:00","relpermalink":"/publication/ma2020contrastive/","section":"publication","summary":"Deep model-based reinforcement learning (MBRL) has achieved great sample-efficiency and generalization in decision making for sophisticated simulated tasks, such as Atari games. However, real-world robot decision making requires reasoning with complex natural visual observations. This paper presents Contrastive Variational Reinforcement Learning (CVRL), an MBRL framework for complex natural observations. In contrast to the commonly used generative world models, CVRL learns a contrastive variational world model by maximizing the mutual information between latent states and observations discriminatively by contrastive learning. Contrastive learning avoids modeling the complex observation space and is significantly more robust than the standard generative world models. For decision making, CVRL discovers long-horizon behavior by online search guided by an actor-critic. CVRL achieves comparable performance with the state-of-the-art (SOTA) generative MBRL approaches on a series of Mujoco tasks, and significantly outperforms SOTAs on Natural Mujoco tasks, a new, more challenging continuous control RL benchmark with complex observations introduced in this paper.","tags":[],"title":"Contrastive Variational Model-Based Reinforcement Learning for Complex Observations","type":"publication"},{"authors":["Jiawei Ren","[Cunjun Yu](https://scholar.google.com.sg/citations?user=CKLBY1QAAAAJ\u0026hl=en)","Shunan Sheng","[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Haiyu Zhao](https://scholar.google.com/citations?user=oGM5N1kAAAAJ)","[Shuai Yi](https://scholar.google.com/citations?user=afbbNmwAAAAJ\u0026hl=en)","[Hongsheng Li](https://scholar.google.com/citations?user=BN2Ze-QAAAAJ\u0026hl=en)"],"categories":[],"content":"","date":1596117103,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596117103,"objectID":"bcc5c0facaf56bf8075b25a4afd5c299","permalink":"/publication/ren2020balanced/","publishdate":"2020-07-30T21:51:43+08:00","relpermalink":"/publication/ren2020balanced/","section":"publication","summary":"Deep classifiers have achieved great success in visual recognition. However, real-world data is long-tailed by nature, leading to the mismatch between training and testing distributions. In this paper, we show that Softmax function, though used in most classification tasks, gives a biased gradient estimation under the long-tailed setup. This paper presents Balanced Softmax, an elegant unbiased extension of Softmax, to accommodate the label distribution shift between training and testing. Theoretically, we derive the generalization bound for multiclass Softmax regression and show our loss minimizes the bound. In addition, we introduce Balanced Meta-Softmax, applying a complementary Meta Sampler to estimate the optimal class sample rate and further improve long-tailed learning. In our experiments, we demonstrate that Balanced Meta-Softmax outperforms state-of-the-art long-tailed classification solutions on both visual recognition and instance segmentation tasks. ","tags":[],"title":"Balanced Meta-Softmax for Long-Tailed Visual Recognition","type":"publication"},{"authors":["Siwei Chen","[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":[],"content":"","date":1595129639,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595129639,"objectID":"a42caa512b5244dbdc9403b6973a17b3","permalink":"/publication/chen-2020-dinerdash/","publishdate":"2020-07-19T11:33:59+08:00","relpermalink":"/publication/chen-2020-dinerdash/","section":"publication","summary":"It has been arduous to assess the progress of a policy learning algorithm in the domain of hierarchical task with high dimensional action space due to the lack of a commonly accepted benchmark. In this work, we propose a new light-weight benchmark task called Diner Dash for evaluating the performance in a complicated task with high dimensional action space. In contrast to the traditional Atari games that only have a flat structure of goals and very few actions, the proposed benchmark task has a hierarchical task structure and size of 57 for the action space and hence can facilitate the development of policy learning in complicated tasks. On top of that, we introduce Decomposed Policy Graph Modelling (DPGM), an algorithm that combines both graph modelling and deep learning to allow explicit domain knowledge embedding and achieves significant improvement comparing to the baseline. In the experiments, we have shown the effectiveness of the domain knowledge injection via a specially designed imitation algorithm as well as results of other popular algorithms. ","tags":[],"title":"DinerDash Gym: A Benchmark for Policy Learning in High-Dimensional Action Space","type":"publication"},{"authors":["[Cunjun Yu*](https://scholar.google.com.sg/citations?user=CKLBY1QAAAAJ\u0026hl=en)","[**Xiao Ma***](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","Jiawei Ren","[Haiyu Zhao](https://scholar.google.com/citations?user=oGM5N1kAAAAJ)","[Shuai Yi](https://scholar.google.com/citations?user=afbbNmwAAAAJ\u0026hl=en)"],"categories":[],"content":"","date":1589982703,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589982703,"objectID":"f5af54bd422ea5a18f77a1fc015d7188","permalink":"/publication/yu2020graph/","publishdate":"2020-05-20T21:51:43+08:00","relpermalink":"/publication/yu2020graph/","section":"publication","summary":"Understanding crowd motion dynamics is critical to real-world applications, e.g., surveillance systems and autonomous driving. This is challenging because it requires effectively modeling the socially aware crowd spatial interaction and complex temporal dependencies. We believe attention is the most important factor for trajectory prediction. In this paper, we present STAR, a Spatio-Temporal grAph tRansformer framework, which tackles trajectory prediction by only attention mechanisms. STAR models intra-graph crowd interaction by TGConv, a novel Transformer-based graph convolution mechanism. The inter-graph temporal dependencies are modeled by separate temporal Transformers. STAR captures complex spatio-temporal interactions by interleaving between spatial and temporal Transformers. To calibrate the temporal prediction for the long-lasting effect of disappeared pedestrians, we introduce a read-writable external memory module, consistently being updated by the temporal Transformer. We show that with only attention mechanism, STAR achieves state-of-the-art performance on 5 commonly used real-world pedestrian prediction datasets. ","tags":[],"title":"Spatio-Temporal Graph Transformer Networks for Pedestrian Trajectory Prediction","type":"publication"},{"authors":["Zuowu Zheng","[Xiaofeng Gao](http://www.cs.sjtu.edu.cn/~gao-xf/)","[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","Guihai Chen"],"categories":[],"content":"","date":1589446805,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589446805,"objectID":"dd4ba60e266f70086754c637f4f710f4","permalink":"/publication/zheng-2020-predicting/","publishdate":"2020-05-14T17:00:05+08:00","relpermalink":"/publication/zheng-2020-predicting/","section":"publication","summary":"Predicting emerging hot events in an early stage is essential for various applications, including information dissemination mining, ads recommendation and etc. Existing techniques either require a long-term observation over the event or features that are expensive to extract. However, given limited data at the early stage of an emerging event, the temporal features of hot events and non-hot events are not distinctive enough yet. In this work, we introduce BEEP, a Bayesian perspective Early stage Event Prediction model, that tackles this dilemma. We formulate the hot event prediction problem by two Semi-Naive Bayes Classifiers, where we consider both the temporal features and structural features and perform distribution test for the selected features. Theoretical analysis and extensive empirical evaluations on two real datasets demonstrate the effectiveness of our methods.","tags":[],"title":"Predicting Hot Events in the Early Period through Bayesian Model for Social Networks","type":"publication"},{"authors":null,"categories":null,"content":"Instructor: Prof. David Hsu\n","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581724800,"objectID":"ae55fee8f7163b2a8362b25f226752b7","permalink":"/teaching/cs5478/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/teaching/cs5478/","section":"teaching","summary":"Instructor: Prof. David Hsu","tags":null,"title":"CS5478: Introduction to Robotics","type":"teaching"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Peter Karkus](https://scholar.google.com.sg/citations?user=cjUid0YAAAAJ\u0026hl=en\u0026oi=ao)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)","[Nan Ye](https://scholar.google.com.sg/citations?user=5XCxGRIAAAAJ\u0026hl=en)"],"categories":[],"content":"","date":1579577639,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579577639,"objectID":"f61e9a697d0d7e183db0b06469da9923","permalink":"/publication/ma-2020-discriminative/","publishdate":"2020-01-21T11:33:59+08:00","relpermalink":"/publication/ma-2020-discriminative/","section":"publication","summary":"Deep reinforcement learning has succeeded in sophisticated games such as Atari, Go, etc. Real-world decision making, however, often requires reasoning with partial information extracted from complex visual observations. This paper presents  Discriminative Particle Filter Reinforcement Learning (DPFRL), a new reinforcement learning framework for partial and complex observations. DPFRL encodes a differentiable particle filter with learned transition and observation models in a neural network, which allows for reasoning with partial observations over multiple time steps. While a standard particle filter relies on a generative observation model, DPFRL learns a discriminatively parameterized model that is training directly for decision making. We show that the discriminative parameterization results in significantly improved performance, especially for tasks with complex visual observations, because it circumvents the difficulty of modelling observations explicitly. In most cases, DPFRL outperforms state-of-the-art POMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and in Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark that we introduce. We further show that DPFRL performs well for visual navigation with real-world data.","tags":[],"title":"Discriminative Particle Filter Reinforcement Learning for Complex Partial Observations","type":"publication"},{"authors":["[**Xiao Ma***](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Peter Karkus*](https://scholar.google.com.sg/citations?user=cjUid0YAAAAJ\u0026hl=en\u0026oi=ao)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":null,"content":"","date":1579478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579478400,"objectID":"4e7bd40d78b5f50f907e151139a73301","permalink":"/publication/1905-12885/","publishdate":"2020-01-20T08:36:27.732217Z","relpermalink":"/publication/1905-12885/","section":"publication","summary":"Recurrent neural networks (RNNs) have been extraordinarily successful for prediction with sequential data. To tackle highly variable and noisy real-world data, we introduce Particle Filter Recurrent Neural Networks (PF-RNNs), a new RNN family that explicitly models uncertainty in its internal structure: while an RNN relies on a long, deterministic latent state vector, a PF-RNN maintains a latent state distribution, approximated as a set of particles. For effective learning, we provide a fully differentiable particle filter algorithm that updates the PF-RNN latent state distribution according to the Bayes rule. Experiments demonstrate that the proposed PF-RNNs outperform the corresponding standard gated RNNs on a synthetic robot localization dataset and 10 real-world sequence prediction datasets for text classification, stock price prediction, etc. ","tags":null,"title":"Particle Filter Recurrent Neural Networks","type":"publication"},{"authors":["[Peter Karkus](https://scholar.google.com.sg/citations?user=cjUid0YAAAAJ\u0026hl=en\u0026oi=ao)","[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Leslie Pack Kaelbling](https://scholar.google.com/citations?user=IcasIiwAAAAJ\u0026hl=en)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)","[Tomas Lozano-Perez](https://scholar.google.ca/citations?user=gQOKAggAAAAJ\u0026hl=en)"],"categories":null,"content":"","date":1558915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558915200,"objectID":"cafbeae19a65b8cb3d55759994272876","permalink":"/publication/1905-11602/","publishdate":"2019-05-31T08:36:27.731933Z","relpermalink":"/publication/1905-11602/","section":"publication","summary":"This paper introduces the Differentiable Algorithm Network (DAN), a composable architecture for robot learning systems. A DAN is composed of neural network modules, each encoding a differentiable robot algorithm and an associated model; and it is trained end-to-end from data. DAN combines the strengths of model-driven modular system design and data-driven end-to-end learning. The algorithms and models act as structural assumptions to reduce the data requirements for learning; end-to-end learning allows the modules to adapt to one another and compensate for imperfect models and algorithms, in order to achieve the best overall system performance. We illustrate the DAN methodology through a case study on a simulated robot system, which learns to navigate in complex 3-D environments with only local visual observations and an image of a partially correct 2-D floor map. ","tags":null,"title":"Differentiable Algorithm Networks for Composable Robot Learning","type":"publication"},{"authors":null,"categories":null,"content":"Instructor: Prof. David Hsu\n","date":1534032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534032000,"objectID":"23ffbf73e63447d4d512323280db5e45","permalink":"/teaching/cs6244/","publishdate":"2018-08-12T00:00:00Z","relpermalink":"/teaching/cs6244/","section":"teaching","summary":"Instructor: Prof. David Hsu","tags":null,"title":"CS6244: Robot Motion Planning and Control","type":"teaching"},{"authors":null,"categories":null,"content":"Instructor: Prof. Yair Zick\n","date":1515974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1515974400,"objectID":"88c800e0f54252dbc020d1a3ffbf6f91","permalink":"/teaching/cs3243/","publishdate":"2018-01-15T00:00:00Z","relpermalink":"/teaching/cs3243/","section":"teaching","summary":"Instructor: Prof. Yair Zick","tags":null,"title":"CS3243: Introduction to Artificial Intelligence","type":"teaching"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Peter Karkus](https://scholar.google.com.sg/citations?user=cjUid0YAAAAJ\u0026hl=en\u0026oi=ao)","[David Hsu](https://scholar.google.com.sg/citations?user=S9LHLKEAAAAJ\u0026hl=en\u0026oi=ao)","[Wee Sun Lee](https://scholar.google.com.sg/citations?user=8PCrLgwAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"b544b7977931930ffa43edc448e910bb","permalink":"/publication/ma-2018-pflstm/","publishdate":"2019-05-31T08:36:27.731156Z","relpermalink":"/publication/ma-2018-pflstm/","section":"publication","summary":"In this work, we explore the combination of Bayesian Filters and Recurrent Neural Networks by introducing the Particle Filter LSTM (PF-LSTM). PF-LSTM replaces the deterministic hidden state of LSTM by a random variable approximated by a set of hidden particles and introduces a stochastic cell update to simulate the stochastic dynamics of the particles. We argue that such Monte-Carlo approximation of the hidden distribution can improve the capability of LSTM on handling the data sequence with high uncertainty, e.g., noisy multi-modal distributions. Empirical experiments show that PF-LSTM is able to outperform the original LSTM in various of tasks.","tags":null,"title":"PF-LSTM: Belief State Particle Filter for LSTM","type":"publication"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Xiaofeng Gao](https://scholar.google.com.sg/citations?hl=en\u0026user=mbGafk4AAAAJ)","[Guihai Chen](https://scholar.google.com.sg/citations?user=rqZWbYgAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"5e886d24e9bf404dfc146a5602d64816","permalink":"/publication/ma-2017-beep/","publishdate":"2019-05-31T08:36:27.731156Z","relpermalink":"/publication/ma-2017-beep/","section":"publication","summary":"In recent years, predicting future hot events in online social networks is becoming increasingly meaningful in marketing, advertisement, and recommendation systems to support companies' strategy making. Currently, most prediction models require long-term observations over the event or depend a lot on other features which are expensive to extract. However, at the early stage of an event, the temporal features of hot events and non-hot events are not distinctive yet. Besides, given the small amount of available data, high noise and complex network structure, those state-of-art models are unable to give an accurate prediction at the very early stage of an event. Hence, we propose two Bayesian perspective models to handle this dilemma. We first mathematically define the hot event prediction problem and introduce the general early stage event prediction framework, then model the five selected features into several continuous distributions, and present two Semi-Naive Bayes Classifier based prediction models, BEEP and SimBEEP, which is the simplified version of BEEP. Extensive experiments on real dataset have demonstrated that our model significantly outperforms the baseline methods.","tags":null,"title":"BEEP: a Bayesian perspective early stage event prediction model for online social networks","type":"publication"},{"authors":["[**Xiao Ma**](https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ\u0026hl=en)","[Zhenzhe Zheng](https://scholar.google.com.sg/citations?user=kx_5xxEAAAAJ\u0026hl=en\u0026oi=ao)","[Fan Wu](http://www.cs.sjtu.edu.cn/~fwu/)","[Guihai Chen](https://scholar.google.com.sg/citations?user=rqZWbYgAAAAJ\u0026hl=en\u0026oi=ao)"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"9348373dec1e326a66acd406d317a0d6","permalink":"/publication/ma-2017-trust/","publishdate":"2019-05-31T08:36:27.73167Z","relpermalink":"/publication/ma-2017-trust/","section":"publication","summary":"The recent proliferation of mobile devices embedded with capable sensors, provides an opportunity to the popular concept of mobile crowdsensing. By studying the correlation of crowd-sensed data in both spatial and temporal dimensions, we can get a clear understanding of the intrinsic pattern of data in mobile crowdsensing, which is the basic for further data analysis, such as data filtering, smoothing and prediction. However, the crowd-sensed data are normally noise and unreliable due to the diverse mobility patterns and selfish behaviours of mobile users, making the classical data models in wireless sensor networks fail in this new context. In this paper, we propose a robust and reliable time series data model based on Dynamic Bayesian Network to describe the characteristics of the crowd-sensed data. The proposed data model can figure out the spatial and temporal correlation of data in the environment, where the data has high noise levels and mobile users are untrustworthy. We conduct extensive evaluations based on both simulation and a real-world data set. Our evaluation results show that our method successfully modeled the crowd-sensed time series data with effectiveness, efficiency and trustworthiness.","tags":null,"title":"Trust-based time series data model for mobile crowdsensing","type":"publication"}]