<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiao Ma's Homepage</title>
  
  <meta name="author" content="Xiao Ma">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiao Ma (马骁)</name>
              </p>
              <p>I am a Research Scientist at Dyson Robot Learning Lab. I obtained my PhD from National University of Singapore, advised by <a href="https://www.comp.nus.edu.sg/~dyhsu/">Prof. David Hsu</a>. I also worked closely with <a href="https://www.comp.nus.edu.sg/~leews/">Prof. Wee Sun Lee</a>. I received my B.Sc. in Computer Science from Shanghai Jiao Tong University in 2017, where I was advised by <a href="http://www.cs.sjtu.edu.cn/~fwu/">Prof. Fan Wu</a> and <a href="http://www.cs.sjtu.edu.cn/~gao-xf/">Prof. Xiaofeng Gao</a>. Previously, I have spent wonderful time at Sea AI Lab, hosted by <a href="https://yanshuicheng.ai/">Prof. Shuicheng Yan</a> and <a href="https://linmin.me/">Dr. Min Lin</a>, and at SenseTime Research, hosted by <a href="https://scholar.google.com.sg/citations?user=afbbNmwAAAAJ&hl=en">Dr. Shuai Yi</a>.
              </p>
              <p>
                <!-- My research focuses on uncertainty modelling, reinforcement learning, graph neural networks, and their applications to robotics. -->
                I'm broadly interested in reinforcement learning, representation learning, information theory, and their applications to robot learning in unstructured environments.
              </p>
              <p>Collaborations and discussions are always welcomed! Please feel free to email me if you're interested.</p>
              <!-- <p style="color:red">I'm looking for research interns to work on topics including multi-agent RL / offline RL. Please reach out if you are interested :)</p> -->
              <p style="text-align:center">
                <a href="mailto:xiao.ma@dyson.com">Email</a> &nbsp/&nbsp
                <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/yusufma555">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/Yusufma03/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/avatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>- [Jun. 2024] 1 paper accepted to RA-L 2024. </p>
            <p>- [Feb. 2024] 1 paper accepted to CVPR 2024.</p>
            <p>- [Sept. 2023] 3 papers accepted to NeurIPS 2023.</p>
            <p>- [Feb. 2023] 1 paper accepted to CVPR 2023.</p>
            <p>- [Feb. 2023] I joined Dyson Robot Learning Lab as a Lead Researcher.</p>
            <p>- [Jan. 2023] 3 papers accepted to ICLR 2023 (1 oral 2 posters)!</p>
            <p>- [Apr. 2022] HILMO for reinforcement learning under mixed observability has been accepted to WAFR 2022!</p>
            <p>- [Feb. 2022] G-DOOM for deformable object manipulation has been accepted to ICRA 2022!</p>
            <!-- <p>- [Jul. 2021] I'm joining <strong>SEA AI Lab</strong> as a research scientist working on reinforcement learning.</p> -->
            <p>- [May 2021] PROMPT for ab-initio object manipulation has been accepted by RSS 2021.</p>
            <p>- [Oct. 2020] CVRL for model-based RL under complex observations has been accepted by CoRL 2020.</p>
            <p>- [Sept. 2020] BALMS for long-tailed visual recognition has been accepted by NeurIPS 2020.</p>
            <p>- [Jul. 2020] STAR for pedestrian trajectory prediction has been accepted by ECCV 2020.</p>
            <p>- [Dec. 2019] DPFRL for reinforcement learning under complex and partial observations has been accepted by ICLR 2020.</p>
            <p>- [Nov. 2019] PF-RNNs for sequence modeling under uncertainty has been accepted to AAAI 2020.</p>
            <p>- [Jun. 2019] DAN was nominated for the <strong>best system paper and best student paper</strong> of RSS 2019!</p>
          </td>
        </tr>
      </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications <a style="font-size:13pt;" href="https://scholar.google.com.sg/citations?user=hR4G6hoAAAAJ&hl=en">(Full publication list)</a></heading>
            </td>
          </tr>
          
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='data/mazzaglia2024redundancy/erj.gif' width="160">
          </td>
          <td style="padding:10px;width:75%;vertical-align:middle">
            <!-- <a href="https://arxiv.org/abs/2305.20081"> -->
            <papertitle>Redundancy-aware Action Spaces for Robot Learning</papertitle>
            <!-- </a> -->
            <br>
            <a href="https://mazpie.github.io/">Pietro Mazzaglia*</a>,
            <a href="https://www.linkedin.com/in/nicholas-backshall/?originalSubdomain=uk">Nicholas Backshall*</a>
            <strong>Xiao Ma</strong>,
            <a href="https://stepjam.github.io/">Stephen James</a> (*equal contributions)
            <br>
            <em>IEEE Robotics and Automation Letters (RA-L),</em> 2024 &nbsp <font color="red"></font>
            <br>
            <a href="https://redundancy-actions.github.io/">project page</a>
            /
            <a href="https://arxiv.org/pdf/2406.04144">pdf</a>
            /
            <a href="https://github.com/mazpie/redundancy-action-spaces">code</a>
            <p>
              We present a new family of action spaces that benefits from both the efficiency from the task space and the flexibility from the joint space for the robotic manipulation.
              </p>
          </td>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='data/ma2024hierarchical/hdp.gif' width="160">
          </td>
          <td style="padding:10px;width:75%;vertical-align:middle">
            <!-- <a href="https://arxiv.org/abs/2305.20081"> -->
            <papertitle>Hierarchical Diffusion Policy for Multi-Task Robotic Manipulation</papertitle>
            <!-- </a> -->
            <br>
            <strong>Xiao Ma</strong>,
            <a href="https://rocketsumit.github.io/">Sumit Patidar</a>,
            <a href="https://www.linkedin.com/in/iain-haughton-194321135/?originalSubdomain=uk">Iain Haughton</a>,
            <a href="https://stepjam.github.io/">Stephen James</a>
            <br>
            <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em> 2024 &nbsp <font color="red"></font>
            <br>
            <a href="https://yusufma03.github.io/projects/hdp/">project page</a>
            /
            <a href="https://arxiv.org/abs/2403.03890">pdf</a>
            /
            <a href="https://github.com/dyson-ai/hdp">code</a>
            <p>Hierarchical Diffusion Policy (HDP) factorises the policy space into a 1) high-level task-planning agent and 2) low-level goal-conditioned diffusion policy, which achieves both task-level generalisation and flexible low-level control.
              </p>
          </td>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='data/ren2023insactor/insactor.gif' width="160">
          </td>
          <td style="padding:10px;width:75%;vertical-align:middle">
            <!-- <a href="https://arxiv.org/abs/2305.20081"> -->
            <papertitle>InsActor: Instruction-driven Physics-based Characters</papertitle>
            <!-- </a> -->
            <br>
            <a href="https://jiawei-ren.github.io/">Jiawei Ren*</a>,
            <a href="https://mingyuan-zhang.github.io/">Mingyuan Zhang</a>,
              <a href="http://cjyu.me/">Cunjun Yu*</a>,
            <strong>Xiao Ma</strong>,
            <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ&hl=zh-CN">Liang Pan</a>,
            <a href="https://scholar.google.com/citations?user=lc45xlcAAAAJ&hl=zh-CN">Ziwei Liu</a>,
            <br>
            <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023 &nbsp <font color="red"></font>
            <br>
            <a href="https://jiawei-ren.github.io/projects/insactor/">project page</a>
            /
            <a href="https://arxiv.org/abs/2312.17135">pdf</a>
            /
            <a href="https://github.com/jiawei-ren/insactor">code</a>
            <p>InsActor is a principled generative framework that leverages recent advancements in diffusion-based human motion models for physics-based human animation generation.</p>
          </td>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src='data/kang2023edp/edp.png' width="160">
          </td>
          <td style="padding:10px;width:75%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2305.20081">
            <papertitle>Efficient Diffusion Policies for Offline Reinforcement Learning</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com.sg/citations?user=NmHgX-wAAAAJ&hl=en">Bingyi Kang*</a>,
            <strong>Xiao Ma*</strong>,
            <a href="https://duchao0726.github.io/">Chao Du</a>,
            <a href="https://p2333.github.io/">Tianyu Pang</a>,
            <a href="https://yanshuicheng.info/">Shuicheng Yan</a> (*equal contributions)
            <br>
            <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023 &nbsp <font color="red"></font>
            <br>
            <a href="https://arxiv.org/abs/2305.20081">pdf</a>
            /
            <a href="https://github.com/sail-sg/edp">code</a>
            <p>We introduce Efficient Diffusion Policies (EDPs), a more general, faster, and better diffusion policy class for offline RL. EDPs reduce the training time of DQL from 5 days to 5 hours!</p>
          </td>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/ma2023misa/misa.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2210.07484">
              <papertitle>Mutual Information Regularized Offline Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Xiao Ma*</strong>,
              <a href="https://scholar.google.com.sg/citations?user=NmHgX-wAAAAJ&hl=en">Bingyi Kang*</a>,
              <a href="https://scholar.google.com.sg/citations?user=T4xuHn8AAAAJ&hl=en">Zhongwen Xu</a>,
              <a href="https://scholar.google.com.sg/citations?user=BGONmkIAAAAJ&hl=en">Min Lin</a>,
              <a href="https://zhongwen.one/">Zhongwen Xu</a>,
              <a href="https://yanshuicheng.info/">Shuicheng Yan</a> (*equal contributions)
              <br>
							<em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2023 &nbsp <font color="red"></font>
              <br>
              <a href="https://arxiv.org/abs/2210.07484">pdf</a>
              /
              <a href="https://github.com/sail-sg/MISA">code</a>
              <p>MISA is a general framework for offline RL motivated by mutual information estimation. We show that both Conservative Q Learning (CQL) and TD3+BC can be considered as its variants.</p>
            </td>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/chen2023ild/ild.gif' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2206.04873">
              <papertitle>Imitation Learning via Differentiable Physics</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen</a>,
              <strong>Xiao Ma</strong>,
              <a href="https://zhongwen.one/">Zhongwen Xu</a>
              <br>
							<em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023 &nbsp <font color="red"></font>
              <br>
              <a href="https://arxiv.org/abs/2206.04873">pdf</a>
              /
              <a href="https://github.com/sail-sg/ILD">code</a>
              /
              <a href="data/chen2023ild/chen2023ild.bib">bibtex</a>
              <p>We present Imitation Learning via Differentiable Physics (ILD), which casts the imitation learning as a state-matching task through differentiable physics-based Chamfer distance loss. ILD significantly improves the sample efficiency and generalization of imitation learning algorithms with only one expert demonstration.</p>
            </td>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/chen2023dax/daxbench.gif' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2210.13066.pdf">
              <papertitle>DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen*</a>,
              <a href="http://cjyu.me/">Cunjun Yu*</a>,
              Yiqing Xu*,
              Linfeng Li,
              <strong>Xiao Ma</strong>,
              <a href="https://zhongwen.one/">Zhongwen Xu</a>,
              <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>
              (*equal contributions)
              <br>
							<em>International Conference on Learning Representations (ICLR)</em>, 2023 &nbsp <font color="red">(Oral)</font>
              <br>
              <a href="https://arxiv.org/pdf/2210.13066.pdf">pdf</a>
              /
              <a href="data/chen2023dax/chen2023dax.bib">bibtex</a>
              <p>We present DaXBench, a comprehensive benchmark for deformable object manipulation, including planning, imitation learning, and reinforcement learning, based on a scalable and differentiable physics simulator coded in JAX.</p>
            </td>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/ren2023diff/diffmimic.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=06mk-epSwZ">
              <papertitle>DiffMimic: Efficient Motion Mimicking with Differentiable Physics</papertitle>
              </a>
              <br>
              <a href="https://jiawei-ren.github.io/">Jiawei Ren*</a>,
              <a href="http://cjyu.me/">Cunjun Yu*</a>,
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen</a>,
              <strong>Xiao Ma</strong>,
              <a href="https://scholar.google.com/citations?user=lSDISOcAAAAJ&hl=zh-CN">Liang Pan</a>,
              <a href="https://liuziwei7.github.io/">Ziwei Liu</a>,
              (*equal contributions)
              <br>
							<em>International Conference on Learning Representations (ICLR)</em>, 2023 &nbsp <font color="red"></font>
              <br>
              <a href="https://diffmimic.github.io/">project page</a>
              /
              <a href="https://openreview.net/forum?id=06mk-epSwZ">pdf</a>
              /
              <a href="https://github.com/jiawei-ren/diffmimic">code</a>
              /
              <a href="https://diffmimic-demo-main-g7h0i8.streamlit.app/">live demo</a>
              /
              <a href="data/ren2023diff/ren2023diff.bib">bibtex</a>
              <p>DiffMimic scales motion imitation for simulated characters with differentiable physics. Training controllers on large-scale motion database is more accessible with DiffMimic.</p>
            </td>      


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='data/qiu2023rpm/rpm.png' width="160">
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=HnSceSzlfrY">
              <papertitle>RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=gszGlZIAAAAJ&hl=en">Wei Qiu</a>,
              <strong>Xiao Ma</strong>,
              <a href="https://personal.ntu.edu.sg/boan/">Bo An</a>,
              <a href="https://scholar.google.com/citations?user=aorQUi0AAAAJ&hl=en">Svetlana Obraztsova</a>,
              <a href="https://scholar.google.com.sg/citations?user=DNuiPHwAAAAJ&hl=en">Shuicheng Yan</a>,
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen*</a>,
              <a href="https://zhongwen.one/">Zhongwen Xu</a>,
              <br>
							<em>International Conference on Learning Representations (ICLR)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2210.09646.pdf">pdf</a>
              /
              <a href="data/qiu2023rpm/qiu2023rpm.bib">bibtex</a>
              <p>We present Ranked Policy Memory (RPM) which simulates unseen agents by ranking history agents in multi-agent RL to encourage better generalization during evaluation.</p>
            </td>



            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>

            <td style="padding:20px;width:25%;vertical-align:left">
              <div class="one">
                <img src='data/ma2021gdoom/gdoom.png' width="160">
              </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/g-doom/">
              <papertitle>Learning Latent Graph Dynamics for Deformable Object Manipulation</papertitle>
              </a>
              <br>
              <strong>Xiao Ma</strong>,
              <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
              <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>,
              <br>
							<em>International Conference on Robotics and Automation (ICRA)</em>, 2022 &nbsp <font color="red"></font>
              <br>
              <a href="https://sites.google.com/view/g-doom/">project page</a>
              /
              <a href="https://arxiv.org/abs/2104.12149">pdf</a>
              /
              <a href="data/ma2021gdoom/ma2021gdoom.bib">bibtex</a>
              <p>We present G-DOOM for deformable object manipulation. G-DOOM abstract an deformable object as a keypoint-based graph and models the spatio-temporal keypoint interactions with Recurrent Graph Dynamics. G-DOOM achieves SOTA performance on a set of deformable object manipulation tasks.</p>
            </td>      

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <td style="padding:20px;width:25%;vertical-align:left">
              <div class="one">
                <img src='data/chen2021prompt/prompt.png' width="160">
              </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://adacomp.comp.nus.edu.sg/2021/06/26/particle-based-robot-manipulation/">
              <papertitle>Ab Initio Particle-based Object Manipulation</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen</a>,
              <strong>Xiao Ma</strong>,
              Yunfan Lu,
              <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
              <br>
							<em>Robotics: Science and Systems (RSS)</em>, 2021 &nbsp <font color="red"></font>
              <br>
              <a href="https://adacomp.comp.nus.edu.sg/2021/06/26/particle-based-robot-manipulation/">project page</a>
              /
              <a href="https://arxiv.org/abs/2107.08865">pdf</a>
              /
              <a href="https://github.com/AdaCompNUS/Prompt">code</a>
              /
              <a href="data/chen2021prompt/chen2021prompt.bib">bibtex</a>
              <p>This paper introduces PROMPT, a framework for particle-based object manipulation. PROMPT performs high-quality online point cloud reconstruction from multi-view images captured by an eye-in-hand camera. It achieves high performance in object grasping, pushing, and placing.</p>
            </td>


            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
            <td style="padding:20px;width:25%;vertical-align:left">
              <div class="one">
                <img src='data/ma2020contrastive/walker.gif' width="160">
              </div>
            </td>
            <td style="padding:10px;width:75%;vertical-align:middle">
              <a href="https://sites.google.com/view/cvrl/">
              <papertitle>Contrastive Variational Reinforcement Learning for Complex Observations</papertitle>
              </a>
              <br>
              <strong>Xiao Ma</strong>,
              <a href="https://scholar.google.com.sg/citations?user=28Wp9rEAAAAJ&hl=en">Siwei Chen</a>,
              <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
              <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>,
              <br>
							<em>In Proceedings of The 4nd Conference on Robot Learning (CoRL)</em>, 2020 &nbsp <font color="red"></font>
              <br>
              <a href="https://sites.google.com/view/cvrl/">project page</a>
              /
              <a href="https://arxiv.org/abs/2008.02430">pdf</a>
              /
              <a href="https://github.com/Yusufma03/CVRL">code</a>
              /
              <a href="https://www.youtube.com/watch?v=koXGdHR6Nd4">talk</a>
              /
              <a href="data/ma2020contrastive/ma2020contrastive.bib">bibtex</a>
              <p>We introduce CVRL, contrastive model-based reinforcement learning for complex observations. Different from standard generative models, CVRL learns a <em>contrastive</em> latent world model and significantly improves the robustness against complex observations.</p>
            </td>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
              <td style="padding:20px;width:25%;vertical-align:left">
                <div class="one">
                  <img src='data/ren2020balanced/balms.png' width="160" height="160">
                </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2007.10740">
                <papertitle>Balanced Meta-Softmax for Long-Tailed Visual Recognition</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com.sg/citations?user=YUKPVCoAAAAJ&hl=en">Jiawei Ren</a>
                <a href="http://cjyu.me/">Cunjun Yu</a>,
                Shunan Sheng,
                <strong>Xiao Ma</strong>,
                <a href="https://scholar.google.com/citations?user=sMQV1ecAAAAJ&hl=zh-CN">Haiyu Zhao</a>,
                <a href="https://scholar.google.com/citations?user=afbbNmwAAAAJ&hl=zh-CN">Shuai Yi</a>,
                <a href="https://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a>
                <br>
                <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020 &nbsp <font color="red"></font>
                <br>
                <a href="https://arxiv.org/abs/2007.10740">pdf</a>
                /
                <a href="https://github.com/jiawei-ren/BalancedMetaSoftmax">code</a>
                /
                <a href="data/ren2020balanced/ren2020balanced.bib">bibtex</a>
                <p>Our key observation is that softmax is biased under the long-tailed distribution. BALMS provides a mathematically unbiased gradient estimate for long-tailed distributions and applies meta-learning to further improve the data sampling process.</p>
              </td>

              <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <td style="padding:20px;width:25%;vertical-align:left">
                <div class="one">
                  <img src='data/chen2020diner/diner.png' width="160">
                </div>
              </td>
              <td style="padding:10px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2007.06207">
                <papertitle>DinerDash Gym: A Benchmark for Policy Learning in High-Dimensional Action Space</papertitle>
                </a>
                <br>
                Siwei Chen,
                <strong>Xiao Ma</strong>,
                <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
                <br>
                <em>In IL workshop, Robotics: Science and Systems (RSS)</em>, 2020 &nbsp <font color="red"></font>
                <br>
                <a href="https://arxiv.org/abs/2007.06207">pdf</a>
                /
                <a href="https://github.com/AdaCompNUS/diner-dash-simulator">code</a>
                /
                <a href="data/chen2020diner/chen2020diner.bib">bibtex</a>
                <p>We present DinerDash Gym, a light-weight benchmark for policy learning with high-dimensional action space. </p>
              </td> -->


              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
                <td style="padding:20px;width:25%;vertical-align:left">
                  <div class="one">
                    <img src='data/yu2020spatio/star.png' width="160" height="160">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2005.08514">
                  <papertitle>Spatio-Temporal Graph Transformer Networks for Pedestrian Trajectory Prediction</papertitle>
                  </a>
                  <br>
                  <a href="http://cjyu.me/">Cunjun Yu*</a>,
                  <strong>Xiao Ma*</strong>,
                  <a href="https://scholar.google.com.sg/citations?user=YUKPVCoAAAAJ&hl=en">Jiawei Ren</a>,
                  <a href="https://scholar.google.com/citations?user=sMQV1ecAAAAJ&hl=zh-CN">Haiyu Zhao</a>,
                  <a href="https://scholar.google.com/citations?user=afbbNmwAAAAJ&hl=zh-CN">Shuai Yi</a>
                  (* equal contributions)
                  <br>
                  <em>European Conference on Computer Vision (ECCV)</em>, 2020 &nbsp <font color="red"></font>
                  <br>
                  <a href="https://sites.google.com/view/star-eccv2020/home">project page</a>
                  /
                  <a href="https://arxiv.org/abs/2005.08514">pdf</a>
                  /
                  <a href="https://github.com/Majiker/STAR">code</a>
                  /
                  <a href="https://www.youtube.com/watch?v=5tS5Xe-DERo">talk</a>
                  /
                  <a href="data/yu2020spatio/yu2020spatio.bib">bibtex</a>
                  <p>We introduce STAR, the first transformer-based pedestrian trajectory predictor. STAR generalizes the Transformers into spatio-temporal graphs and significantly improves the trajectory prediction accuracy (2x).</p>
                </td>

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
                  <td style="padding:20px;width:25%;vertical-align:left">
                    <div class="one">
                      <img src='data/ma2020discriminative/dpfrl.gif' width="160" height="160"> 
                    </div>
                  </td>
                  <td style="padding:10px;width:75%;vertical-align:middle">
                    <a href="https://sites.google.com/view/dpfrl">
                    <papertitle>Discriminative Particle Filter Reinforcement Learning for Complex Partial Observations</papertitle>
                    </a>
                    <br>
                    <strong>Xiao Ma</strong>,
                    <a href="http://karkus.tilda.ws/">Peter Karkus</a>,
                    <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
                    <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>,
                    <br>
                    <em>International Conference on Learning Representations (ICLR)</em>, 2020 &nbsp <font color="red"></font>
                    <br>
                    <a href="https://sites.google.com/view/dpfrl/">project page</a>
                    /
                    <a href="https://openreview.net/forum?id=HJl8_eHYvS">pdf</a>
                    /
                    <a href="https://github.com/Yusufma03/DPFRL">code</a>
                    /
                    <a href="https://iclr.cc/virtual_2020/poster_HJl8_eHYvS.html">talk</a>
                    /
                    <a href="data/ma2020discriminative/ma2020discriminative.bib">bibtex</a>
                    <p>We introduce DPFRL for reinforcement learning for complex partial observations. DPFRL encodes a <em>discriminative particle algorithm</em> as a differentiable computational graph in neural networks which improves the belief tracking.</p>
                  </td>

                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
                    <td style="padding:20px;width:25%;vertical-align:left">
                      <div class="one">
                        <img src='data/ma2020particle/pfrnn.png' width="160" height="160"> 
                      </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/1905.12885">
                      <papertitle>Particle Filter Recurrent Neural Networks</papertitle>
                      </a>
                      <br>
                      <strong>Xiao Ma*</strong>,
                      <a href="http://karkus.tilda.ws/">Peter Karkus*</a>,
                      <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
                      <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>
                      (* equal contributions)
                      <br>
                      <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 &nbsp <font color="red"></font>
                      <br>
                      <a href="https://arxiv.org/abs/1905.12885">pdf</a>
                      /
                      <a href="https://github.com/Yusufma03/pfrnns">code</a>
                      /
                      <a href="data/ma2020particle/ma2020particle.bib">bibtex</a>
                      <p>We introduce PF-RNNs for general sequence prediction under uncertainty. PF-RNNs encodes a differentiable particle filter algorithm with standard RNNs and improves the general sequence prediction performance.</p>
                    </td>

                    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
                      <td style="padding:20px;width:25%;vertical-align:left">
                        <div class="one">
                          <img src='data/karkus2019differentiable/dan.png' width="160" height="160"> 
                        </div>
                      </td>
                      <td style="padding:10px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/abs/1905.11602">
                        <papertitle>Differentiable Algorithm Networks for Composable Robot Learning</papertitle>
                        </a>
                        <br>
                        <a href="http://karkus.tilda.ws/">Peter Karkus</a>,
                        <strong>Xiao Ma</strong>,
                        <a href="https://www.comp.nus.edu.sg/~dyhsu/">David Hsu</a>,
                        <a href="https://scholar.google.com/citations?user=IcasIiwAAAAJ&hl=en">Leslie Kaelbling</a>,
                        <a href="https://www.comp.nus.edu.sg/~leews/">Wee Sun Lee</a>
                        <a href="https://scholar.google.ca/citations?user=gQOKAggAAAAJ&hl=en">Tomas Lozano-Perez</a>
                        <br>
                        <em>Robotics: Science and Systems (RSS)</em>, 2019 &nbsp <font color="red">best system paper finalist & best student paper finalist</font>
                        <br>
                        <a href="https://arxiv.org/abs/1905.11602">pdf</a>
                        /
                        <a href="data/karkus2019differentiable/karkus2019dan.bib">bibtex</a>
                        <p>A DAN is composed of neural network modules, each encoding a differentiable algorithm and an associated model; and it is trained end-to-end from data. The algorithms and models act as structural priors to reduce the data requirements for learning; end-to-end learning allows the modules to adapt to one another and compensate for imperfect models and algorithms. </p>
                      </td>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Stolen from <a href="https://github.com/jonbarron/website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
